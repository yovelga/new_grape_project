\chapter{Materials and Methods}
\label{ch:materials_methods}

\noindent
This chapter details the experimental design, data acquisition procedures, and computational methodologies employed to detect grape cracking using hyperspectral imaging under field conditions. To address the research objectives, the methodology is organized into three progressive phases:

\begin{enumerate}
    \item \textbf{Data Acquisition:} Describes the commercial vineyard experimental setup, the multi-modal sensor suite (HSI, RGB, and Thermal), and the field collection protocols.
    \item \textbf{Dataset Construction:} Details the formulation of the pixel-level and whole-image datasets, including the use of an interactive annotation pipeline powered by foundation vision models (SAM2) for precise spectral extraction.
    \item \textbf{Modeling and Evaluation Framework:} Outlines the end-to-end analytical pipeline, progressing from global spectral preprocessing and baseline pixel-level classification to robust whole-image spatial aggregation and strategic wavelength selection.
\end{enumerate}

\medskip
% -----------------------------
% DATA ACQUISITION
% -----------------------------
\clearpage
\section{Data Acquisition}

\subsection{Study Area and Experimental Design}

\noindent
The study was conducted in the Lachish region of Israel, a semi-arid area characterized by hot, dry summers and mild winters, making it a central hub for Israeli viticulture. Figure~\ref{fig:lachish_landscape} shows a view of the Lachish vineyard environment. The experiment took place in a commercial table grape vineyard (\textit{Vitis vinifera} L., cv. `Scarlotta'), operated in collaboration with the ``Tali Grapes'' brand. The vineyard was planted in 2018 and grafted onto 1103 Paulsen rootstock.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{figures/materials_methods/study_area/lachish_vineyard_row_2.png}
    \caption{A general view of the Lachish vineyard (Row~2) illustrating the semi-arid landscape and vine rows.}
    \label{fig:lachish_landscape}
\end{figure}

\medskip
\noindent
The experimental layout followed a Randomized Complete Block Design (RCBD) comprising five replicates (Blocks A--E). Within each block, four distinct irrigation regimes were applied, yielding a total of 20 experimental plots ($5~\text{blocks} \times 4~\text{treatments}$). The two panels in Figure~\ref{fig:vineyard_example} summarize the block structure and irrigation assignment and provide an example of a tagged grape cluster used for repeated imaging; together they establish the spatial provenance for the row-based calibration and testing sets used later in this study.

\medskip
\noindent
Each experimental plot consisted of three consecutive rows of nine vines. To minimize edge effects and water spillover between treatments, only vines from the middle row of each plot were monitored. From these middle rows, 12 representative grape clusters were tagged per plot, resulting in a total sample size of 240 monitored clusters. To ensure accurate repeated imaging throughout the season, these target clusters were marked with durable, color-coded tags indicating their specific irrigation regime, and their vine locations were georeferenced using a GPS module.

\medskip
\noindent
The four irrigation regimes, initiated on April 29, 2024, and applied via drip irrigation, were:
\begin{itemize}
    \item \textbf{High Irrigation (Blue):} 796 mm of water throughout the season.
    \item \textbf{Low Irrigation (White):} 376 mm of water throughout the season.
    \item \textbf{Reducing Irrigation (Red):} Transition from high to low irrigation (total 532 mm), commencing post-veraison.
    \item \textbf{Increasing Irrigation (Yellow):} Transition from low to high irrigation (total 645 mm), commencing post-veraison.
\end{itemize}

\medskip
\noindent
The experimental campaign ran continuously until late September 2024. Alongside the imaging procedures detailed below, weekly physiological and yield measurements---including stem water potential, stomatal conductance, and soil moisture---were collected to provide agronomic context for the spectral analyses.


\begin{figure}[H]
    \centering
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/materials_methods/study_area/vineyard_map.png}
        \caption{Map of the experimental vineyard showing the five randomized blocks (A--E) and the four irrigation regimes applied within each block.}
        \label{fig:vineyard_map}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/materials_methods/study_area/grape_with_plastic_tag.png}
        \caption{Tagged grape cluster used for tracking and repeated imaging; tags indicate the specific irrigation regime.}
        \label{fig:grape_tag}
    \end{subfigure}
    \caption{(a) Vineyard map with randomized blocks and irrigation treatments; (b) example of a plastic-tagged grape cluster.}
    \label{fig:vineyard_example}
\end{figure}

\subsection{Multi-Modal Imaging Systems}

\noindent
A multi-modal sensor suite was deployed to capture complementary spectral, spatial, and thermal data. The three imaging systems were co-located and operated from a fixed working distance of approximately 1~m from the target grape clusters, ensuring consistent scale across all modalities.

\subsubsection{Hyperspectral Imaging System (HSI)}
\noindent
Hyperspectral data were acquired using the \textbf{Specim IQ} (Specim, Spectral Imaging Ltd., Oulu, Finland), a portable snapshot camera operating in the Visible and Near-Infrared (VNIR) range (400--1000~nm). Figure~\ref{fig:hsi_setup} illustrates the field deployment of the system, highlighting the complex background and illumination conditions inherent to vineyard acquisition.

\begin{figure}[htbp]
    \centering
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/materials_methods/equipment/taking_picture_with_hsi.jpg}
        \caption{Hyperspectral image acquisition of grape clusters using the Specim IQ.}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/materials_methods/study_area/hyperspectral_imaging_of_plants.png}
        \caption{The Hyperspectral Data Cube Structure.}
    \end{subfigure}
    \caption{Hyperspectral imaging setup and data acquisition using the Specim IQ system under vineyard conditions.}
    \label{fig:hsi_setup}
\end{figure}
\FloatBarrier

\begin{itemize}
    \item \textbf{Spectral Resolution:} The sensor captures 204 contiguous bands with a Full Width at Half Maximum (FWHM) of 7~nm and a spectral sampling interval of $\approx$3~nm. High signal fidelity is maintained by a signal-to-noise ratio (SNR) of $>400\!:\!1$.
    \item \textbf{Spatial Resolution:} The camera features a $512 \times 512$ pixel sensor. With a $31^\circ \times 31^\circ$ Field of View (FOV), the 1~m working distance provides a physical coverage of $\approx 0.55 \times 0.55$~m, yielding a theoretical spatial resolution of \textbf{1.08~mm/pixel}---sufficient for resolving individual berries and macroscopic cracks.
    \item \textbf{Radiometric Calibration:} A spectrally flat, diffuse white reference panel (Spectralon\textsuperscript{\textregistered}, $\approx99\%$ reflectance) was placed within every scene to enable accurate conversion of raw radiance to relative reflectance, compensating for dynamic ambient illumination.
\end{itemize}

\subsubsection{RGB Imaging System}
\noindent
High-resolution visual RGB Imaging System , a \textbf{Canon EOS R5} digital camera was utilized. Equipped with a 45-megapixel full-frame CMOS sensor ($8192 \times 4608$ pixels) and a \textbf{35~mm} prime lens, the system provided a wide FOV ($54.4^\circ \times 37.8^\circ$). At the standard 1~m working distance, this configuration achieved an extreme spatial resolution of approximately \textbf{0.13~mm/pixel}. This fine resolution is essential for identifying hairline fissures and cuticular alterations prior to their visibility in the HSI data.

\subsubsection{Thermal Imaging System}
\noindent
Surface temperatures of the canopy and clusters were monitored using a \textbf{FLIR T1020} (Teledyne FLIR LLC, USA) high-definition thermal camera (Figure~\ref{fig:thermal_setup}). This uncooled microbolometer operates in the Long-Wave Infrared (LWIR) range ($7.5$--$14~\mu$m) with a resolution of $1024 \times 768$ pixels. Equipped with a \textbf{34~mm} lens and boasting a high thermal sensitivity (NETD $<20$~mK at $30^\circ$C), the system achieved a spatial resolution of \textbf{0.81~mm/pixel} at 1~m. This allowed for precise extraction of berry surface temperatures, minimizing mixed-pixel effects from surrounding foliage.

\begin{figure}[htbp]
    \centering
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/materials_methods/equipment/yovel_with_thermal_camera.jpg}
        \caption{FLIR T1020 thermal camera used for vineyard measurements.}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/materials_methods/equipment/thermal_image_with_decay_and_cracksjpg.jpg}
        \caption{Thermal image of a grape cluster showing surface temperature variations.}
    \end{subfigure}
    \caption{Thermal imaging system and example thermal data acquired from grape clusters under vineyard conditions.}
    \label{fig:thermal_setup}
\end{figure}

\FloatBarrier

\medskip
\noindent
The combined multi-modal imaging campaign generated a substantial data footprint. On average, a single HSI datacube required $\approx 200$~MB, compared to 11~MB for RGB and 2.5~MB for thermal images. The entire season's dataset exceeded \textbf{575~GB}, necessitating robust computational infrastructure for downstream processing.

\subsection{Data Collection Protocol}

\noindent
Data collection was conducted on dedicated field days, typically once per week from June through late September. To manage the different operational requirements of the sensors and to leverage specific environmental conditions, a structured diurnal sampling strategy was implemented:

\begin{itemize}
    \item \textbf{Early Morning (RGB):} Image acquisition commenced between 07:00 and 08:00. All 240 target clusters were imaged first using the RGB system to capture baseline visual conditions under relatively uniform, soft morning lighting.
    \item \textbf{Mid-Morning (HSI):} Hyperspectral acquisition began at approximately 10:00 when solar illumination was more intense and stable. Because the HSI setup required manual re-positioning, white reference placement, and dedicated spectral focusing for each shot, a single scan took 2--3 minutes. Consequently, a representative subset of 120 clusters was imaged per session, alternating coverage across field days to encompass the entire experimental layout.
    \item \textbf{Midday (Thermal):} Thermal imaging was purposely scheduled for peak heat hours (starting around 12:00). Utilizing the high ambient temperatures of the semi-arid Negev region maximizes thermal contrast on the berry surface. Cracked or decaying tissues---characterized by exposed moisture or altered transpirational cooling---exhibit distinct thermal signatures compared to intact skin, making them significantly more detectable under peak thermal load.
\end{itemize}

\medskip
\noindent
All imaging systems were spatially co-aligned to the target clusters during acquisition. While this thesis focuses primarily on the analysis of the RGB and HSI datasets, the temporal and spatial synchronization of all three modalities provides a foundation for future integrative multi-sensor fusion.
% -----------------------------
% PREPROCESSING
% -----------------------------

\clearpage
\section{Dataset Construction and Partitioning}
\label{sec:dataset_construction}

\noindent
Transforming raw hyperspectral datacubes into machine-learning-ready datasets required precise spatial annotation and rigorous partitioning. The dataset construction was divided into two levels: an extracted pixel-level dataset for spectral characterization and baseline modeling, and a whole-image dataset for evaluating spatial aggregation under field conditions.

\subsection{Interactive Pixel-Level Annotation via SAM2}
\label{subsec:dataset_pixel}

\noindent
To enable accurate extraction of spectral signatures for both the binary (\textit{Cracked} vs. \textit{Healthy}) and multi-class problem formulations, a custom graphical user interface (GUI) was developed in Python. This tool integrated data visualization, interactive annotation, and automated segmentation into a single streamlined platform (Figure~\ref{fig:gui_sam2_pixelpicker}).

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=1\linewidth]{figures/materials_methods/gui/gui_sam2_pointer_with_numbers.png}
    \caption{Graphical user interface of the HSI--RGB annotation tool. (1) Hyperspectral image visualized as an RGB composite with a SAM2-generated segmentation overlay, (2) wavelength-selectable grayscale HSI band, and (3) high-resolution RGB image of the same cluster. (4) Spectral signature extracted from a pixel within the segmented region, and (5) autoencoder reconstruction of the signature.}
    \label{fig:gui_sam2_pixelpicker}
\end{figure}
\FloatBarrier

\medskip
\noindent
The annotation workflow leveraged foundation vision models to overcome the low spatial resolution of the HSI data. The procedure operated as follows:
\begin{enumerate}
    \item \textbf{Interactive Seeding:} The user selected a seed pixel on a target object (e.g., a cracked berry, intact tissue, leaf, or background element) using either the high-resolution RGB image or the HSI composite.
    \item \textbf{SAM2 Segmentation:} The seed pixel served as a point prompt for the \textbf{Segment Anything Model 2 (SAM2)} \cite{ravi2024sam2}. SAM2 generated a precise binary mask of the object on the RGB image, which was subsequently spatially aligned and projected onto the hyperspectral datacube.
    \item \textbf{Spectral Extraction:} The tool extracted the 204-band spectral vectors for all pixels within the projected mask. The user assigned a definitive class label to the region, and the grouped signatures were stored along with their parent cluster ID and acquisition date.
\end{enumerate}

\medskip
\noindent
This process was initially used to build a binary dataset containing strictly healthy and cracked grape tissues. It was subsequently expanded to build a comprehensive 10-class multi-class dataset, incorporating diverse vineyard background elements (e.g., leaves, branches, soil, plastic covers, and metallic tripod parts) to train robust classifiers capable of rejecting non-grape clutter. The definitions and distributions of these classes are summarized in Table~\ref{tab:multiclass_pixel_distribution}.

\begin{table}[htbp]
\centering
\small
\setlength{\tabcolsep}{6pt}
\begin{tabularx}{\linewidth}{@{} l r X @{}}
\toprule
\textbf{Class} & \textbf{Pixels} & \textbf{Description} \\
\midrule
BACKGROUND       & 378{,}194 & Soil, ground, and mixed non-object pixels. \\
WHITE\_REFERENCE & 270{,}159 & Calibration panel pixels. \\
TRIPOD          & 137{,}494 & Camera tripod and imaging setup components. \\
LEAF            & 120{,}552 & Green vine foliage. \\
BRANCH           & 78{,}654 & Woody vine structures (stem, cane). \\
REGULAR          & 69{,}618 & Intact grape tissue without visible defects. \\
PLASTIC          & 66{,}185 & Artificial vineyard elements (covers, ties). \\
BURNT\_PIXEL      & 36{,}676 & Saturated or overexposed pixels. \\
CRACK            & 24{,}548 & Grape tissue exhibiting visible cracking symptoms. \\
IRON              & 6{,}961 & Metallic elements (wires, stakes). \\
\bottomrule
\end{tabularx}


\caption{Multi-class pixel-level dataset: exported pixels by class.}
\label{tab:multiclass_pixel_distribution}
\end{table}

\clearpage
\subsection{Whole-Image Dataset Formulation}
\label{subsec:whole_image_dataset}

\noindent
While pixel-level data are essential for training core spectral classifiers, operational evaluation requires inference on full spatial scenes. The whole-image dataset is structured at the \emph{(grape\_id, week\_date)} level, with each record corresponding to a complete hyperspectral datacube of a cluster.

\medskip
\noindent
To rigorously evaluate the system's early-warning capabilities, the whole-image dataset was stratified into two distinct acquisition conditions based on the progression of the disorder at the time of measurement:
\begin{itemize}
    \item \textbf{Early-stage:} The earliest available image associated with the onset of cracking for the same cluster, representing the initial observable stage.
    \item \textbf{Late-stage:} Images acquired after the first recorded cracking event, representing an advanced cracking condition.
\end{itemize}

\medskip
\noindent
The exact sample distributions for these stages are detailed in Table~\ref{tab:dataset_statistics}. The spatial partitioning of these images to simulate a realistic early-warning scenario and prevent information leakage is detailed in Section~\ref{subsec:leakage_control}.
\begin{figure}[htbp]
    \centering
    \fbox{\begin{minipage}{0.96\linewidth}
    \centering
    Row split $\rightarrow$ Train pixel-level model on pixels from Late-stage (Row~1) $\rightarrow$ Tune full-image aggregation hyperparameters on Row~1 (separately for Early/Late) $\rightarrow$ Freeze parameters $\rightarrow$ Inference on held-out evaluation set (Row~2) $\rightarrow$ Stage-specific reporting (Early/Late)
    \end{minipage}}
    \caption{Protocol overview for the row-based split, training and calibration on Row~1 Late-stage data, held-out evaluation on Row~2, and post-inference reporting stratified by acquisition stage.}
    \label{fig:whole_image_protocol_overview}
\end{figure}

\begin{table}[htbp]
    \centering
    \small
    \renewcommand{\arraystretch}{1.3}
    \begin{tabular}{@{} l l r r r @{} }
        \toprule
        \textbf{Dataset} & \textbf{Split / Variant} & \textbf{Samples} & \textbf{Positive} & \textbf{Negative} \\
        & & & \textbf{(CRACK)} & \textbf{(REGULAR)} \\
        \midrule
        Pixel-Level Binary & Exported labeled pixels & 94{,}166 & 24{,}548  & 69{,}618  \\
        Pixel-Level Multi-Class & Exported labeled pixels & 1{,}189{,}041 & 24{,}548 & 69{,}618$^*$ \\
        \midrule
        Whole-Image Early & Row~1 calibration  & 172 & 32 & 140 \\
        Whole-Image Early & Row~2 test  & 60 & 32 & 28 \\
        \midrule
        Whole-Image Late & Row~1 calibration  & 160 & 35 & 125 \\
        Whole-Image Late & Row~2 test  & 60 & 34 & 26 \\
        \bottomrule
    \end{tabular}
    \caption{Exact dataset statistics used in the experiments. $^*$Note: The negative class in the multi-class pixel dataset also includes the background classes detailed in Table~\ref{tab:multiclass_pixel_distribution}.}
    \label{tab:dataset_statistics}
\end{table}

\FloatBarrier



% -----------------------------
% MODELING AND EVALUATION
% -----------------------------
\section{Modeling and Evaluation Methodology}
\label{sec:modeling_evaluation}

\noindent
This section outlines the computational frameworks used to analyze the hyperspectral data, progressing from fundamental spectral preprocessing to robust pixel-level classification and anomaly detection.

\subsection{Global Spectral Preprocessing}
\label{subsec:global_preprocessing}

\noindent
To ensure methodological uniformity and prevent information leakage \cite{thenkabail2016hyperspectral}, all hyperspectral datacubes were subjected to a strictly fixed preprocessing pipeline prior to any model training or evaluation.

\begin{itemize}
    \item \textbf{Spectral Range Restriction:} Raw signatures were cropped to the 450--925\,nm range (159 contiguous bands). This step discarded extreme wavelengths (400--450\,nm and 925--1000\,nm) known to exhibit low signal-to-noise ratios and reflectance artifacts under outdoor field conditions \cite{behmann2018specim}.
    \item \textbf{Per-Spectrum Normalization:} Each remaining spectral vector was independently normalized using the \textit{Standard Normal Variate} (SNV) transformation. By mean-centering and scaling each pixel exclusively by its own standard deviation, SNV mitigates illumination variability and scattering effects without relying on dataset-level statistics. This strictly per-pixel approach intrinsically prevents data leakage between training and testing partitions \cite{mishra2017close, kaltenborn2025data}.
\end{itemize}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.7\textwidth]{figures/literature/snv_normalization_effect.png}
    \caption{Effect of Standard Normal Variate (SNV) normalization on hyperspectral reflectance signatures for four representative material classes (Crack, Regular Berry, Plastic, Branch). Left column: raw reflectance spectra showing the mean (solid line) and $\pm 1$ standard deviation band (shaded region), illustrating substantial baseline and amplitude differences due to illumination variability and surface scattering. Right column: corresponding SNV-normalized spectra, in which each signature is mean-centered and scaled by its standard deviation, removing multiplicative and additive effects while preserving the class-discriminative spectral shape. Statistics computed over 500 sampled pixels per class.}
    \label{fig:snv_effect}
\end{figure}
\FloatBarrier

\subsection{Data Partitioning and Leakage Prevention Strategies}
\label{subsec:leakage_control}

\noindent
A foundational principle of this study was the strict prevention of spatial and spectral information leakage. Because hyperspectral vineyard data exhibit strong spatial autocorrelation, improper data splitting would artificially inflate model performance. To ensure robust evaluation, distinct leakage prevention strategies were enforced at both the pixel and whole-image levels.

\subsubsection{Pixel-Level Leakage Prevention: Leave-One-Group-Out (LOGO)}
\label{subsec:cv_strategy}
\noindent
At the pixel level, contiguous pixels extracted from the same grape cluster share highly correlated spectral signatures. To prevent leakage, every extracted pixel was rigidly associated with its parent \emph{cluster ID} and \emph{acquisition date} (as defined in \S\ref{subsec:dataset_pixel}). This metadata was used to enforce a \textbf{Leave-One-Group-Out (LOGO)} cross-validation strategy. Under this protocol, all pixels originating from the same physical cluster were strictly assigned to either the training set or the test set in their entirety. For the multi-class formulation, a domain-aware LOGO variant was implemented: grape-containing acquisitions were folded using standard LOGO, while non-grape background samples (e.g., soil, leaves) were allocated to a fixed 80/20 hold-out split to prevent semantic leakage.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.55\textwidth]{figures/materials_methods/example4group_logo.png}
    \caption{Illustration of the Leave-One-Group-Out (LOGO) cross-validation strategy. In each fold, all pixels from one grape cluster (group) are held out as the test set, while pixels from all remaining clusters form the training set. This ensures that no spatially correlated pixels from the same physical cluster appear in both partitions simultaneously.}
    \label{fig:logo_illustration}
\end{figure}
\FloatBarrier

\subsubsection{Whole-Image Leakage Prevention: Spatial Row Partitioning}
\noindent
At the whole-image level, evaluating the early-warning framework required simulating a realistic deployment scenario on unseen vines. To prevent spatial autocorrelation between adjacent vines, a strict geographical partitioning scheme was enforced. All hyperspectral records acquired from vineyard \textbf{Row 1} were designated exclusively as the calibration and training set, while records from \textbf{Row 2} served as the held-out evaluation (test) set. Because the two rows are physically disjoint (separated by distance and foliage), this row-based split robustly evaluates the model's ability to generalize to entirely new regions of the vineyard.

\medskip
\noindent
Crucially, to simulate a true early-warning application, the underlying pixel-level models used in the whole-image pipeline were trained \textit{exclusively} on pixels extracted from \textbf{Late-stage} images in Row 1. Early-stage records were entirely hidden from the pixel-level training phase. The whole-image aggregation hyperparameters were tuned strictly on Row 1, frozen, and then applied blindly to the Row 2 held-out set.
\subsection{Pixel-Level Classification Framework}
\label{subsec:pixel_level_framework}

\noindent
Supervised classification was applied at the pixel level to discriminate between cracked tissue, healthy tissue, and background elements based solely on their SNV-normalized spectral signatures (159 bands).

\medskip
\noindent
\textbf{Problem Formulations:} The classification was evaluated under two primary settings:
\begin{itemize}
    \item \textbf{Binary:} Classifying pixels strictly as \textit{Healthy} ($y=0$) or \textit{Cracked} ($y=1$).
    \item \textbf{Multi-class:} Classifying pixels into the full 10-class taxonomy (incorporating background elements) to test robustness against vineyard clutter.
\end{itemize}

\medskip
\noindent
\textbf{Algorithm Selection and Training:} Six algorithms were evaluated: Partial Least Squares Discriminant Analysis (PLS-DA), L1-regularized Logistic Regression, Support Vector Machine (RBF kernel), Random Forest, a shallow Multi-Layer Perceptron (MLP), and \textbf{XGBoost} (Gradient-boosted decision trees). XGBoost was ultimately adopted as the baseline model across all primary comparisons due to its robust handling of high-dimensional, correlated spectral features. Models were evaluated under both naturally unbalanced and strictly balanced training regimes (achieved via segment-proportional undersampling to preserve within-class diversity).

\newpage
\subsection{Autoencoder-Based Anomaly Detection}
\label{subsec:anomaly_detection}

\noindent
To explore whether crack damage could be identified without explicit positive labels, a one-class anomaly detection framework was implemented using a fully connected, symmetric autoencoder.

\medskip
\noindent
The autoencoder (optimized via Adam, MSE loss) was trained exclusively on a designated ``normal'' class (e.g., healthy pixels). During inference, the anomaly score for a given spectrum $x$ was defined as its reconstruction error, $e(x) = \frac{1}{D}\lVert x-\hat{x} \rVert_2^2$. An operating threshold $\tau$ was established at the $99^{\mathrm{th}}$ percentile of the training errors. For integration into the whole-image pipeline, reconstruction errors were mapped to probability-like crack scores via a sigmoid function:
\begin{equation}
    p_{\mathrm{CRACK}}(x) = \frac{1}{1 + \exp\left(\frac{e(x) - \tau}{\alpha}\right)}
\label{eq:ae_score_mapping}
\end{equation}
where $\alpha \approx 0.3\tau$ served as a temperature parameter controlling the sharpness of the transition.

\clearpage
\subsection{Whole-Image Detection and Aggregation Pipeline}
\label{subsec:full_image_pipeline}

\noindent
\textit{How can spatial context stabilize noisy pixel-level outputs into reliable image-level decisions?}

\medskip
\noindent
The whole-image pipeline aggregates pixel-wise crack probability maps produced by the trained multi-class pixel-level classifier into image-level decisions. All upstream pixel-level models were fixed at their trained states and were not retrained or tuned at the image level.

\subsubsection{Pipeline Architecture and Spatial Aggregation}

\noindent
The whole-image aggregation pipeline follows a sequential process, illustrated in
Figure~\ref{fig:whole_image_protocol_overview}, and consists of the following stages:

\begin{enumerate}
    \item \textbf{Probability Map Generation:} The trained multi-class XGBoost model processes the full input datacube ($H \times W \times 159$), producing a dense crack probability map $P_{\mathrm{CRACK}} \in [0,1]^{H \times W}$.
    \item \textbf{Morphological Integration:} To enforce spatial coherence, adjacent pixels with elevated crack probabilities are connected using morphological closing operations. This bridges tiny gaps in hairline micro-cracks and suppresses isolated noisy pixels, forming continuous regions of interest (BLOBs).
    \item \textbf{Geometric Filtering:} The resulting connected components are filtered based on area constraints. BLOBs smaller than a defined minimum area are discarded as noise, while structurally valid regions are retained.
    \item \textbf{Patch-Based Decision Logic:} The filtered probability map is divided into fixed-size spatial patches. A patch is classified as crack-positive if the density of crack-related pixels within its boundaries exceeds a calibrated threshold.
    \item \textbf{Global Image-Level Inference:} The final image-level decision employs a dual-condition logic to maximize noise rejection. The entire cluster is flagged as \textit{Cracked} only if both of the following conditions are met simultaneously: (1) at least one spatial patch satisfies the crack-positive criteria, \textbf{and} (2) the global proportion of crack-related pixels across the entire image exceeds a predefined overall density threshold. If either condition is not met, the image is classified as \textit{Non-Cracked}.
\end{enumerate}


% \begin{figure}[htbp]
%     \centering
%     \includegraphics[width=0.9\textwidth]{figures/materials_methods/pipeline/whole_image_pipeline.jpg}
%   \caption{Whole-image crack-detection pipeline from pixel-level CRACK probabilities to image-level classification via spatial aggregation.}
% \end{figure}
% \FloatBarrier

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{figures/materials_methods/pipeline/ui_for_EDA_with_notes.JPG}
    \caption{Interactive EDA interface for the whole-image detection pipeline.
    \textbf{(1)}~Sample browser: loads HSI datacube by cluster ID and date.
    \textbf{(2)}~Model and filter panel: loads the pre-trained model and Optuna-tuned spatial parameters; includes a band selector for panel~7.
    \textbf{(3)}~Canon RGB photo.
    \textbf{(4)}~Raw HSI-camera RGB.
    \textbf{(5)}~Crack detections after blob filtering on RGB.
    \textbf{(6)}~Patch-based crack overlay on RGB.
    \textbf{(7)}~Grayscale HSI band at the selected wavelength.
    \textbf{(8)}~Raw pixel-level crack probability map.
    \textbf{(9)}~Blob map after morphological and area filtering.
    \textbf{(10)}~Patch-based detection map (here similar to~9, as crack regions fit within single patches).}
    \label{fig:ui_eda_pipeline}
\end{figure}
\FloatBarrier

% \subsection{Whole-Image Detection and Spatial Aggregation Pipeline}
% \label{subsec:full_image_pipeline}

% \noindent
% \textit{How can spatial context stabilize noisy pixel-level outputs into reliable image-level decisions?}

% \medskip
% \noindent
% While the pixel-level classifier is highly sensitive to spectral alterations, applying it directly to a full hyperspectral scene often yields isolated false positives due to background clutter or sensor noise. The whole-image pipeline addresses this by aggregating pixel-wise crack probabilities into robust, spatially coherent image-level decisions. All upstream pixel-level models were fixed at their trained states and were not retrained during this stage.

% \subsubsection{Spatial Aggregation Algorithm}
% \noindent
% The transformation from pixel probabilities to a final image diagnosis follows a sequential spatial aggregation algorithm:

% \begin{enumerate}
%     \item \textbf{Probability Map Generation:} The trained multi-class XGBoost model processes the full input datacube ($H \times W \times 159$), producing a dense crack probability map $P_{\mathrm{CRACK}} \in [0,1]^{H \times W}$.
%     \item \textbf{Morphological Integration:} To enforce spatial coherence, adjacent pixels with elevated crack probabilities are connected using morphological closing operations. This bridges tiny gaps in hairline micro-cracks and suppresses isolated noisy pixels, forming continuous regions of interest (BLOBs).
%     \item \textbf{Geometric Filtering:} The resulting connected components are filtered based on area constraints. BLOBs smaller than a defined minimum area are discarded as noise, while structurally valid regions are retained.
%     \item \textbf{Patch-Based Decision Logic:} The filtered probability map is divided into fixed-size spatial patches. A patch is classified as crack-positive if the density of crack-related pixels within its boundaries exceeds a calibrated threshold.
%     \item \textbf{Global Image-Level Inference:} The final severity decision is aggregated globally. The entire cluster is flagged as \textit{Cracked} if at least one patch satisfies the positive criteria, ensuring a highly sensitive yet noise-resistant early-warning trigger.
% \end{enumerate}

\FloatBarrier
\subsubsection{Calibration and Evaluation Stratification}
\noindent
The spatial hyperparameters for the aggregation stages (e.g., morphological kernel sizes, minimum BLOB area, and patch density thresholds) were optimized exclusively on the \textbf{Row 1} dataset using the \textbf{Optuna} hyperparameter optimization framework. By automating the search space exploration on the calibration set, this approach avoids manual tuning bias. Finally, to evaluate robust generalization across the timeline of the disorder, the frozen parameters were applied blindly to the \textbf{Row 2} held-out set and stratified by disease progression (\textbf{Early-stage} vs. \textbf{Late-stage}), directly addressing \hyperref[hyp:whole_image_robustness]{Hypothesis~3} and \hyperref[hyp:early_detection]{Hypothesis~4}.
\FloatBarrier

\subsection{Wavelength Selection}
\label{subsec:wavelength_selection}

\noindent
\textit{How many wavelengths are needed to maintain crack-detection performance?}

\medskip
\noindent
This stage evaluates whether a reduced subset of wavelengths can maintain crack-detection
performance while preserving physical interpretability for potential multispectral sensor design. BFS was applied exclusively at the pixel level; whole-image inference used
pixel-level models trained on either the full or reduced spectral representation without
additional wavelength adaptation at the image level.

% \medskip
% \noindent
% With the full detection pipeline established---from pixel-level classification through spatial aggregation---the final methodological question was whether the complete 159-band spectral representation was necessary, or whether a reduced wavelength set could preserve detection performance while simplifying future sensor requirements. BFS was applied exclusively at the pixel level; whole-image inference used pixel-level models trained on either the full or reduced spectral representation without additional wavelength adaptation at the image level.

\medskip
\noindent
Wavelength selection was evaluated separately for binary (\textit{Cracked} vs.\ \textit{Healthy}) and multi-class (with background classes) settings, as formulated in \S\ref{subsec:pixel_level_framework}.

\clearpage
\subsubsection{Spectral Preprocessing}

\noindent
Pixels were preprocessed as described in \S\ref{subsec:global_preprocessing} (SNV normalization, 450--925\,nm range, 159 bands).

\subsubsection{Classification Model}

\noindent
XGBoost was used as the fixed classifier for all wavelength selection experiments, consistent with the baseline model adopted in the pixel-level classification framework (\S\ref{subsec:pixel_level_framework}).

\subsubsection{Two Experimental Settings}

\noindent
Wavelength selection was performed in two independent experiments:
\begin{itemize}[leftmargin=1.5em,nosep]
    \item \textbf{Binary setting:} Wavelengths selected for \textit{Cracked} vs.\ \textit{Healthy} classification.
    \item \textbf{Multi-class setting:} Wavelengths selected for multi-class classification with background classes.
\end{itemize}

\subsubsection{Train-Test Split Protocol}
A single grouped 80/20 hold-out split was defined to prevent leakage, with grouping
at the grape-cluster level in the binary setting and at the cluster level for
background classes in the multi-class setting. At each BFS iteration, XGBoost was
re-trained on the 80\% training partition, while the held-out 20\% test partition
remained fixed and served as the invariant selection criterion.

\subsubsection{Backward Feature Selection (BFS)}

\noindent
A deterministic wrapper-based backward feature selection (BFS) procedure was applied,
starting from the full set of 159 wavelengths and iteratively removing the least
informative band at each step. At each iteration, XGBoost was re-trained on the 80\%
training partition and evaluated on the fixed 20\% hold-out set, using PR--AUC--CRACK
as the selection criterion. This procedure yielded a monotonic elimination path and
identified the minimal wavelength subset that preserved near-baseline performance.

\medskip
\noindent
To assess the stability of the selected wavelength subsets, the BFS procedure
was repeated five times. The random seed supplied to the XGBoost model
was kept fixed, while the seed controlling the grouped 80/20 train--test
data partition was varied (split seeds 1--5). This approach evaluates the
robustness of the wavelength selection process against variations in the data splitting.

% Implementation reference (grouped 80/20 BFS split + leakage assertions):
% src/models/classification/pixel_level/feature_selection/run_bfs_80_20_grapeid.py
% src/models/classification/pixel_level/feature_selection/run_bfs_prauc_stability_5runs.py

\clearpage
\subsection{Evaluation Protocols and Performance Metrics}
\label{subsec:evaluation_protocols}

Model training and model-selection procedures were evaluated using
PR--AUC\textsubscript{CRACK} as the primary ranking metric across all
pixel-level classification, anomaly detection, and wavelength-selection
experiments, reflecting the strong class imbalance at the pixel level.
Whole-image crack detection was evaluated using
F1\textsubscript{CRACK} as the primary system-level metric.
Unless explicitly subscripted, reported F1 refers to the weighted F1-score.


\subsection{Reproducibility and Implementation Details}

All experiments were executed in Python using fixed random seeds (default seed = 42) to ensure deterministic data splits and model training. Cross-validation partitions and held-out test sets were kept invariant across runs. Experiment outputs were stored in timestamped directories together with configuration files and cross-validation manifests to enable exact reruns of the reported pipelines.



% Modeling and Evaluation Methodology
% |--- Global Spectral Preprocessing
% |--- Spectral Discriminability and Informative Wavelength Analysis
% |  +--- Feature selection as a derived outcome
% |--- Pixel-Level Classification Framework
% |  |--- Binary Pixel-Level Classification
% |  +--- Multi-Class Pixel-Level Classification
% |--- Anomaly Detection Framework (One-Class)
% |--- Wavelength Selection via Backward Feature Selection (BFS)
% |  |--- For binary pixel-level models
% |  +--- For multi-class pixel-level models
% |--- Whole-Image Detection and Aggregation Pipeline
% |--- Evaluation Protocols
% |  |--- Leave-One-Group-Out (LOGO) cross-validation
% |  +--- Performance Metrics

